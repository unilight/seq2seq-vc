
###########################################################
#                  FINE-TUNING SETTING                    #
###########################################################
init-mods: ["encoder", "decoder", "feat_out", "prob_out", "postnet"]
freeze-mods: null

###########################################################
#                   INFERENCE SETTING                     #
###########################################################
vocoder:
    checkpoint: ./downloads/pwg_slt/checkpoint-400000steps.pkl
    config: ./downloads/pwg_slt/config.yml
    stats: ./downloads/pwg_slt/stats.h5
inference:
    threshold: 0.5    # threshold to stop the generation
    maxlenratio: 6.0 # maximum length of generated samples = input length * maxlenratio
    minlenratio: 0.0  # minimum length of generated samples = input length * minlenratio

###########################################################
#                  DATA LOADER SETTING                    #
###########################################################
batch_size: 100             # Batch size.
pin_memory: true            # Whether to pin memory in Pytorch DataLoader.
num_workers: 2              # Number of workers in Pytorch DataLoader.
allow_cache: true           # Whether to allow cache in dataset. If true, it requires cpu memory.

###########################################################
#             OPTIMIZER & SCHEDULER SETTING               #
###########################################################
optimizer_type: Adam
optimizer_params:
    lr: 0.00008              # Learning rate. See https://github.com/espnet/espnet/blob/master/espnet2/schedulers/noam_lr.py#L49-L50
grad_norm: 1.0              # Gradient norm.
scheduler: warmuplr
scheduler_params:
    warmup_steps: 4000      # Scheduler warm up step

###########################################################
#                    INTERVAL SETTING                     #
###########################################################
train_max_steps: 50000                 # Number of training steps.
save_interval_steps: 100               # Interval steps to save checkpoint.
eval_interval_steps: 100               # Interval steps to evaluate the network.
log_interval_steps: 10                 # Interval steps to record the training log.